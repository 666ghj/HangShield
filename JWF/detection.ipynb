{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:05:18.190493600Z",
     "start_time": "2024-09-03T12:05:18.013744500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5288\n",
      "62\n",
      "277\n",
      "251\n",
      "4\n",
      "标签 0.0 的聚类中心:\n",
      "[0.020778664036241228, -0.1107728924560077, -0.999987806352702, -0.999930273538286, 0.999970971969041, -0.9999997465989806, 0.4952956178365285, -0.9999965962767603, 0.6450491573623466, 0.12920219359242066, -0.908094710284336, 0.0018033446976911116, 0.5390994121185081, -0.6465078733567231, -0.00775905302937345, -0.6836763584546073, -0.11717744146537143, 0.4038425559817738, 0.9999976416609504, 0.9951054403456775, 0.010362772689047423, 0.00023291296921554294, -0.1299322992864937, -0.026254004518182654, -0.10341237716016971, 0.7846414644042541, 0.9177546322413456, -0.40933765950327017, -0.8431863678839395, -0.9232045119069501, -0.7715133050576238, 0.2567498012865493]\n",
      "[-0.5696281870596649, -0.7249936931315322, -0.7742798783889007, -0.9627719194004216, 0.8936955583156997, -0.9675197052087674, -0.26335533282517937, -0.7516245501173523, 0.9739728699639897, 0.9924911855806392, -0.7735772390437033, -0.21797094335698178, -0.2717892385063901, 0.992183862203138, 0.5015720941701828, 0.970339676207796, -0.6293497207126881, -0.7805853529847675, 0.937093142727294, 0.9832240308682944, -0.2614408374322366, 0.6593505440145428, -0.2625318809284004, 0.1566501658059387, 0.8519694292476178, -0.9743311963514576, 0.3090399031918589, -0.1123898968035142, 0.951955769710318, 0.9745814231502816, 0.3301663565840678, -0.9851455906002786]\n",
      "[0.15237964424108963, 0.7197225730658635, -0.9991189013459527, -0.9999165070631011, 0.9981317641714814, -0.9989944429922148, -0.547868605864381, -0.9982615917273803, -0.057406445235679615, 0.27901246850189754, -0.973947023942968, 0.6816850715836573, -0.20775425840455886, -0.40557584055190216, 0.07790535886419017, -0.7740368869109919, -0.3254689888486056, 0.1281615399551729, 0.9999446032517805, 0.9915022602950322, 0.0012696153092647822, 0.02702616404863331, -0.03972180602909978, 0.09857475660183483, -0.16269962384325495, 0.6893824184109165, 0.3935266329526081, 0.7092154384331242, -0.510758392824833, -0.42248521012415025, -0.7642274837007854, -0.634818166517674]\n",
      "标签 1.0 的聚类中心:\n",
      "[0.0522264391183854, -0.3204606303146907, 0.5803218941603387, -0.8232029846736364, -0.6439551753657203, -0.41780000073569185, -0.27883220996175506, 0.8523246347904205, 0.720147213765553, 0.8610230684280396, 0.09293610176869826, -0.24690299906900948, 0.10360268317162989, 0.7848039822919028, 0.7078406552651098, 0.7174621522426605, -0.827010596969298, -0.925897491829736, 0.7028229492051262, 0.9981346598693303, -0.6959156649453301, 0.7983198080744062, -0.37141652919152485, 0.3081882642582059, 0.8425955857549395, -0.8233277435813631, 0.15763416779892803, -0.46916428527661724, 0.9164235613175802, 0.7521120304507867, 0.6503334109272274, -0.879176642213549]\n",
      "[0.2809646095741879, 0.6363498675213622, -0.9999908154661007, -0.9998067183928057, 0.9999999810348856, -0.9999996775930577, -0.4371782297437842, -1.0000000000000002, 0.8884107118303125, 0.3661298291249709, -0.9034727239473299, -0.5774816979061473, 0.9049866748127068, -0.03416556119918823, -0.35603119809688505, 0.363636542450298, -0.1386059637774121, -0.14791282723573126, 0.9998346106572584, 0.9890000413764607, -0.020115256584672697, 0.31368036889894435, 0.22366653552109544, 0.011333124775608827, 0.8843528655442323, 0.653494313274595, 0.899971674789082, -0.8595957701856441, -0.06418091185531183, -0.9886496988209807, 0.3709716417572714, -0.5416688350113955]\n",
      "[-0.7465430326186696, -0.9764001690424403, -0.9999770201169529, -0.9999974645101107, 0.9991905643389776, -0.9999992503569677, -0.5954059137103077, -0.9999999954150275, 0.7239804588831388, 0.9999558237882761, -0.9218663796782495, -0.49323082084839154, -0.6170794407908736, 0.7178392272729142, 0.36283444011440635, 0.538702932687906, -0.31577105648242515, -0.2617865634652285, 0.999988317489624, 0.9501382754399226, -0.10294618389497576, 0.5134398839794673, 0.05421783617482735, 0.4595158255587404, 0.29791164627441974, -0.9576257238021266, 0.810612385089581, 0.6403494912844439, 0.8723422675751724, 0.783241873463759, -0.3742801873013379, -0.9215879669556251]\n",
      "标签 2.0 的聚类中心:\n",
      "[0.044348949757148245, 0.29575158029934007, -0.9999879274781296, -0.9999261611089931, 0.9999992960081324, -0.9999996695931502, -0.06639586805409964, -0.9999999999999998, 0.1714814605675342, 0.09226080153401472, -0.9751166053644316, 0.5419445121514169, 0.4781818665476063, -0.5648936556622868, -0.1146320718538574, -0.7161267869115804, -0.2820675205659325, 0.34019006339935765, 0.9999892195378701, 0.9925256437204015, 0.014681641071554147, 0.03354419541923814, -0.09754243449676477, 0.05761624175842529, -0.013793723584395068, 0.604189418102284, 0.4283458867410972, 0.5276799546921348, -0.5513758392139233, -0.5624915455453339, -0.6849824758026534, -0.09998438843181234]\n",
      "[-0.03136509437771405, 0.4759960332337544, -0.9999882421072793, -0.9911195101106868, 0.9999999921111499, -0.9999994994962916, -0.9635283701560083, -0.9998832923524518, 0.029323246549156967, 0.9995899919201341, -0.901163151159006, -0.1510082220056039, -0.6782629912828696, 0.999739490887698, 0.5224024388829578, 0.9121417420751916, -0.33077154711902346, -0.8584870064959811, 0.9998307648827048, 0.9920211478191263, -0.3250691201092732, 0.6423577815294268, 0.09192825753501994, 0.7734586560331723, 0.2502353388596985, -0.9428445501800837, -0.3859049220576283, 0.5439593516399751, 0.9877580930204942, 0.9728038170758408, 0.8061178971958517, -0.992403488825349]\n",
      "[-0.3886629610276984, -0.8442312457212594, -0.49153261068390647, -0.9083662912613009, 0.8400722731177398, -0.9576571869959192, 0.1273504314239974, -0.47825869808836663, 0.975544294206107, 0.9944503074739033, -0.7547615951881176, -0.9007704217815986, 0.2763873689421795, 0.9828194405247526, 0.5638099694397395, 0.9014800387184807, -0.45358121349680713, -0.25779687049912264, 0.8604899259602151, 0.9545805824965965, -0.3402246062575681, 0.5511941427092364, -0.1108002220166894, -0.1245040178139944, 0.8214503348600573, -0.9948428687525948, 0.33060760955076396, -0.2606508415646664, 0.982528925668901, 0.9440351630129458, 0.1682477840790297, -0.9814412957284506]\n",
      "标签 3.0 的聚类中心:\n",
      "[-0.08620027517995887, 0.18065076266396252, -0.9999871671814278, -0.999967263531439, 0.9999920264961794, -0.9999996601920766, -0.15574157717589698, -1.0000000000000002, 0.7115102960276847, 0.9610567271094961, -0.9692707424311293, 0.08978442042662765, 0.1854193567000714, -0.03341772061647802, 0.13925861605663878, -0.5843002433629383, -0.12377398437100334, 0.3239101493711944, 0.9999793331647657, 0.9899745073515115, 0.003032076371456846, 0.08050817288830386, -0.02210452669712981, 0.07596314070955142, -0.46706646496487547, 0.1280063529086019, 0.8454749479736245, 0.39685880400470885, -0.4539803330277661, -0.21379556921646764, -0.7129403165320758, -0.520688818549238]\n",
      "[0.279913149682093, 0.4854688439395604, -0.9999898627952292, -0.9998856437059096, 0.9999961860385942, -0.9999997056560752, -0.07784707808614136, -1.0000000000000002, -0.02671271562576316, -0.9545645978715684, -0.9680525594287449, 0.6854893854692768, 0.5818788326448867, -0.7731130564654324, -0.8134696592151373, -0.9258685295964459, -0.4365950523427239, 0.35510566004230093, 0.9999913036087413, 0.9966696280020254, 0.019581736870294006, -0.014316360058010236, -0.18944765055152576, 0.026238126134108995, 0.10012652504223361, 0.8920252332808805, 0.012637320859932244, 0.5092831357025808, -0.6376425890183003, -0.7452525083941454, -0.8016531493192834, 0.28929442719176984]\n",
      "[-0.6554704806576025, -0.7635552633477191, -0.5926936178991238, -0.9969094371142453, 0.8115409812698625, -0.9490739401072672, -0.04752569104710661, -0.6104621919867114, 0.9948871364332222, 0.983023465904471, -0.7986948918997732, -0.2780668057552341, -0.7206021491182985, 0.9998803065247722, 0.672525983712037, 0.917929923697693, -0.6951478588815834, -0.8664998244749346, 0.9047374792703211, 0.9625228831212814, -0.35330377699016285, 0.6404836105361372, -0.4439550319507921, -0.1255655297881935, 0.9531875236393662, -0.9541233176850287, 0.419603571142644, 0.09428667853114348, 0.9925096671875211, 0.9173010114121096, 0.24534492685829556, -0.9896549443676039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Nine_Dream\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import random\n",
    "\n",
    "data_dir = './data/feat'\n",
    "# data_be = np.load(os.path.join(data_dir, 'be.npy'))\n",
    "ben = np.load(os.path.join(data_dir, 'BEN.npy'))\n",
    "rat = np.load(os.path.join(data_dir, 'RAT.npy'))\n",
    "pst = np.load(os.path.join(data_dir, 'PST.npy'))\n",
    "spt = np.load(os.path.join(data_dir, 'SPT.npy'))\n",
    "\n",
    "p = 0.8\n",
    "ben_len = int(ben.shape[0] * p)\n",
    "rat_len = int(rat.shape[0] * p)\n",
    "pst_len = int(pst.shape[0] * p)\n",
    "spt_len = int(spt.shape[0] * p)\n",
    "\n",
    "print(ben_len)\n",
    "print(rat_len)\n",
    "print(pst_len)\n",
    "print(spt_len)\n",
    "# data_ma = np.load(os.path.join(data_dir, 'ma.npy'))\n",
    "# other = np.load(os.path.join(data_dir, 'other.npy'))\n",
    "# print(train_data_ma.shape)\n",
    "# print(train_data_be.shape)\n",
    "data = np.concatenate([ben[:ben_len, :], rat[: rat_len, :], pst[:pst_len, :], spt[ :spt_len, :]], axis=0)\n",
    "test_ma = np.concatenate([ben[ben_len:, :], rat[rat_len: , :], pst[pst_len: , :], spt[spt_len:, :]], axis=0)\n",
    "\n",
    "features = data[:, :-1]  \n",
    "labels = data[:, -1]     \n",
    "\n",
    "cluster_centers_dict = {}\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "print(len(unique_labels))\n",
    "for label in unique_labels:\n",
    "    # all features on label_now\n",
    "    label_features = features[labels == label]\n",
    "    \n",
    "    k = 3\n",
    "    \n",
    "    # K-Means\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(label_features)\n",
    "    \n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    cluster_centers_dict[label] = cluster_centers.tolist()\n",
    "\n",
    "for label, centers in cluster_centers_dict.items():\n",
    "    print(f\"标签 {label} 的聚类中心:\")\n",
    "    for center in centers:\n",
    "        print(center)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测标签: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 3.0, 0.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 2.0, 3.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 2.0, 2.0, 3.0, 0.0, 3.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 3.0, 3.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0]\n",
      "真实标签: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.56      0.70      1323\n",
      "           1       0.02      0.25      0.04        16\n",
      "           2       0.06      0.13      0.08        70\n",
      "           3       0.08      0.46      0.14        63\n",
      "\n",
      "    accuracy                           0.53      1472\n",
      "   macro avg       0.28      0.35      0.24      1472\n",
      "weighted avg       0.86      0.53      0.64      1472\n",
      "\n",
      "Accuracy: 0.5285\n",
      "Precision: 0.8636\n",
      "Recall: 0.5285\n",
      "F1 Score: 0.6419\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data_dir = './data/feat'\n",
    "test_data = test_ma#np.load(os.path.join(data_dir, 'test.npy'))\n",
    "# test_data = np.concatenate([test_data, test_ma], axis=0)\n",
    "# data_ma = np.load(os.path.join(data_dir, 'ma.npy'))\n",
    "\n",
    "test_features = test_data[:, :-1]\n",
    "true_labels = test_data[:, -1]\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "\n",
    "for test_vector in test_features:\n",
    "    max_similarity = -1  \n",
    "    predicted_label = None\n",
    "    \n",
    "    for label, centers in cluster_centers_dict.items():\n",
    "        similarities = cosine_similarity([test_vector], centers)\n",
    "        \n",
    "        max_label_similarity = np.max(similarities)\n",
    "        \n",
    "        if max_label_similarity > max_similarity:\n",
    "            max_similarity = max_label_similarity\n",
    "            predicted_label = label\n",
    "    \n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, labels=[0, 1, 2, 3])\n",
    "\n",
    "\n",
    "print(f\"预测标签: {predicted_labels}\")\n",
    "print(f\"真实标签: {true_labels.tolist()}\")\n",
    "print(report)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:05:21.431760100Z",
     "start_time": "2024-09-03T12:05:19.966451300Z"
    }
   },
   "id": "d4dff537277371f9"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nine_Dream\\AppData\\Local\\Temp\\ipykernel_28792\\168189274.py:64: UserWarning: You passed a edgecolor/edgecolors ('black') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  plt.scatter(reduced_centers[indices, 0], reduced_centers[indices, 1],\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument must be a color, a sequence of colors, or a sequence of numbers, not 'darkpurple'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4433\u001B[0m, in \u001B[0;36mAxes._parse_scatter_color_args\u001B[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001B[0m\n\u001B[0;32m   4432\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:  \u001B[38;5;66;03m# Is 'c' acceptable as PathCollection facecolors?\u001B[39;00m\n\u001B[1;32m-> 4433\u001B[0m     colors \u001B[38;5;241m=\u001B[39m \u001B[43mmcolors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_rgba_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4434\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\matplotlib\\colors.py:471\u001B[0m, in \u001B[0;36mto_rgba_array\u001B[1;34m(c, alpha)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(c, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 471\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m is not a valid color value.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    473\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(c) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: 'darkpurple' is not a valid color value.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 64\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(all_center_labels)):\n\u001B[0;32m     63\u001B[0m     indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mwhere(all_center_labels \u001B[38;5;241m==\u001B[39m label)\n\u001B[1;32m---> 64\u001B[0m     \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduced_centers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduced_centers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m                \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcenter_colors\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcenter_colors\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmarkers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmarkers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m                \u001B[49m\u001B[43ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medgecolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mblack\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCluster Center \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mlabel\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# 绘制测试特征向量\u001B[39;00m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(true_labels)):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\matplotlib\\pyplot.py:2862\u001B[0m, in \u001B[0;36mscatter\u001B[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001B[0m\n\u001B[0;32m   2857\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mscatter)\n\u001B[0;32m   2858\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter\u001B[39m(\n\u001B[0;32m   2859\u001B[0m         x, y, s\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, c\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2860\u001B[0m         vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, linewidths\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   2861\u001B[0m         edgecolors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, plotnonfinite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2862\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2863\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2864\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinewidths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlinewidths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2865\u001B[0m \u001B[43m        \u001B[49m\u001B[43medgecolors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medgecolors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplotnonfinite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplotnonfinite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2866\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2867\u001B[0m     sci(__ret)\n\u001B[0;32m   2868\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\matplotlib\\__init__.py:1446\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1443\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1444\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1446\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1448\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1449\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1450\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4596\u001B[0m, in \u001B[0;36mAxes.scatter\u001B[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001B[0m\n\u001B[0;32m   4593\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edgecolors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4594\u001B[0m     orig_edgecolor \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medgecolor\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   4595\u001B[0m c, colors, edgecolors \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m-> 4596\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_scatter_color_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medgecolors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mget_next_color_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_patches_for_fill\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_next_color\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4600\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m plotnonfinite \u001B[38;5;129;01mand\u001B[39;00m colors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   4601\u001B[0m     c \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mmasked_invalid(c)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env_audio\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4442\u001B[0m, in \u001B[0;36mAxes._parse_scatter_color_args\u001B[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001B[0m\n\u001B[0;32m   4439\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m invalid_shape_exception(c\u001B[38;5;241m.\u001B[39msize, xsize) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   4440\u001B[0m         \u001B[38;5;66;03m# Both the mapping *and* the RGBA conversion failed: pretty\u001B[39;00m\n\u001B[0;32m   4441\u001B[0m         \u001B[38;5;66;03m# severe failure => one may appreciate a verbose feedback.\u001B[39;00m\n\u001B[1;32m-> 4442\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   4443\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m argument must be a color, a sequence of colors, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4444\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor a sequence of numbers, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   4445\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4446\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(colors) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, xsize):\n\u001B[0;32m   4447\u001B[0m         \u001B[38;5;66;03m# NB: remember that a single color is also acceptable.\u001B[39;00m\n\u001B[0;32m   4448\u001B[0m         \u001B[38;5;66;03m# Besides *colors* will be an empty array if c == 'none'.\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: 'c' argument must be a color, a sequence of colors, or a sequence of numbers, not 'darkpurple'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_centers = []\n",
    "all_center_labels = []\n",
    "\n",
    "for label, centers in cluster_centers_dict.items():\n",
    "    all_centers.extend(centers)\n",
    "    all_center_labels.extend([label] * len(centers))\n",
    "\n",
    "all_data = np.vstack([test_features, np.array(all_centers)])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(all_data)\n",
    "\n",
    "reduced_test_data = reduced_data[:len(test_features)]\n",
    "reduced_centers = reduced_data[len(test_features):]\n",
    "\n",
    "max_test_points = min(len(reduced_test_data), 500) \n",
    "max_center_points = min(len(reduced_centers), 500) \n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "if len(reduced_test_data) > max_test_points:\n",
    "    sampled_test_indices = np.random.choice(len(reduced_test_data), max_test_points, replace=False)\n",
    "    reduced_test_data = reduced_test_data[sampled_test_indices]\n",
    "    true_labels = true_labels[sampled_test_indices]\n",
    "    predicted_labels = predicted_labels[sampled_test_indices]\n",
    "\n",
    "if len(reduced_centers) > max_center_points:\n",
    "    sampled_center_indices = np.random.choice(len(reduced_centers), max_center_points, replace=False)\n",
    "    reduced_centers = reduced_centers[sampled_center_indices]\n",
    "    all_center_labels = np.array(all_center_labels)[sampled_center_indices]\n",
    "\n",
    "center_colors = ['darkred', 'darkblue', 'darkgreen', 'darkpurple', 'darkorange', 'darkcyan']\n",
    "sample_colors = ['lightcoral', 'lightblue', 'lightgreen', 'mediumpurple', 'lightsalmon', 'paleturquoise']\n",
    "markers = ['o', 'x', '^', 's', 'P', 'D']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, label in enumerate(np.unique(all_center_labels)):\n",
    "    indices = np.where(all_center_labels == label)\n",
    "    plt.scatter(reduced_centers[indices, 0], reduced_centers[indices, 1],\n",
    "                c=center_colors[i % len(center_colors)], marker=markers[i % len(markers)],\n",
    "                s=200, edgecolor='black', alpha=0.9, label=f'Cluster Center {label}')\n",
    "\n",
    "for i, label in enumerate(np.unique(true_labels)):\n",
    "    indices = np.where(true_labels == label)\n",
    "    plt.scatter(reduced_test_data[indices, 0], reduced_test_data[indices, 1],\n",
    "                c=sample_colors[i % len(sample_colors)], marker=markers[i % len(markers)],\n",
    "                s=100, alpha=0.6, label=f'Test Point {label}')\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Cluster Centers and Test Points Visualization')\n",
    "plt.legend()\n",
    "plt.savefig('./pca.png')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T14:20:30.928127700Z",
     "start_time": "2024-09-01T14:20:29.894087100Z"
    }
   },
   "id": "af7891b0dcfdf874"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f588da709a60729"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
